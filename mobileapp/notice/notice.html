<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" type="text/css" href="Semantic/semantic.min.css">
    <script src="Semantic/semantic.min.js"></script>
    <title>notice</title>
</head>
<body>
<div class="ui inverted vertical masthead center aligned segment">

          <h1 class="ui inverted header">
            爬虫编写过程中遇到的问题
        </h1>
    <div class="text container">
        <h3>
            所有的模块
        </h3>
        <p>
            应当统一添加数据规范化处理模块，所以最后存储的时候应当调用一个规范化功能的函数。规范化成item中的字段格式
        </p>
        <p>
            注意字段中的数据类型，比如reply_count应当是int类型，而不是string。
        </p>
    </div>


    <div class="center blue aligned column">
        <div class="center aligned column"></div>

    </div>

</div>
<div class="ui vertical masthead aligned segment">
    <div class="ui middle aligned stackable grid container">
        <div class="html ui top attached segment">
            <div class="ui bulleted list">
                <div class="item">
                    <h2 style="color: red">
                        即时：注意事项
                    </h2>
                    <div class="ui bulleted list">
                        <div class="item">
                            像澎湃新闻里边的那种没有抓取到内容的评论，应该舍弃掉，所以应该有一个单独的模块，在数据的流的最末端，做一个判断，如果不合适就舍弃，并log记录之。
                        </div>
                        <div class="item">
                            spider_time统一在最后添加。
                        </div>
                        <div class="item">
                            临时添加了params这个字段，之前数据库里边一直没有
                        </div>
                        <div class="item">
                                最终的规范化模块，比如时间戳的处理，可能有问题
                        </div>
                        <div class="item">
                            今天在今日头条中发现，deal_comment的数据return之后，没有进入pipeline中。所以yield和return不能同时使用。
                        </div>
                        <div class="item">
                            pipeline功能和standroid模块的功能有重复。
                        </div>
                        <div class="item">
                            依赖库:pyexecjs,pymongo,scrapy,scrapyd,redis。
                        </div>
                        <div class="item">
                            今日头条过滤掉了不少，一会检查是怎么回事。
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>
</div>
<div class="ui vertical masthead aligned segment">
        <div class="ui middle aligned stackable grid container">
            <div class="html ui top attached segment">
                <div class="ui bulleted list">
                    <div class="item">
                        <h2>
                            thepaper
                        </h2>
                        <div class="list">
                            <div class="item">
                                <a class="ui label">
                                    完成
                                </a>
                                可能video_urls有问题

                            </div>
                            <div class="item">
                                视频中的id，不是board某一个新闻标题下的id，而是具体连接后的以"_"开头的数字，因为后边要根据这个字段的值来请求评论。
                            </div>
                            <div class="item">
                                突发问题，请求中，里边请求链接本来应该先在board_next中处理一下，但是在yield请求的时候，发现callback设置错误，导致有些board中并没有按照设置的来顺序来处理。有些boardlist的请求时针对网页版的，版面和app版的不一样，不过应该只是在这个地方有差别。article和movie的都有问题。实际情况是请求的response中没有结果。
                            </div>
                            <div class="item">
                                reply_count中有3.1k这种写法。注意转数字
                            </div>
                            <div class="item">
                                注意字典用法的update，update用法中谁update谁？不过用新数据update旧数据，那么就数据会覆盖新数据，所以会出现：经过content处理函数处理过后的字典，最终url不是这个content的，而是board的。所以应当是metadata.update(new_dict)这种比较多
                            </div>
                            <div class="item">
                                img_urls里边有错误，没有前边的host。
                            </div>
                            <div class="item">
                                一个包含视频的新闻：http://www.thepaper.cn/newsDetail_forward_2063366。不是来自于视频板块的。
                            </div>
                            <div class="item">
                                回复数中，在boardList中抓到的回复数并不是真的回复数，这里边把每一个like_count也算上了，所以reply_count会远远大于实际的reply_count
                            </div>
                            <div class="item">
                                http://m.thepaper.cn/newsDetail_forward_2040309，这个链接里边的内容是文章类型，但是并不适用其它的一般的xpath文章规则。
                            </div>

                        </div>
                        <h2>
                            jiemian
                        </h2>
                        <div class="list">
                            <div class="item">
                                在处理content字段的函数中，里边返回的json数据，包含了content，而且是html格式的。content_dealed = content_response_json.unquote(content_raw)；这个方法可以解析出内容。
                            </div>
                            <div class="item">
                                澎湃只有前20条评论，抓不到更多的。~~~
                            </div>
                        </div>
                        <h2>
                            huanqiu
                        </h2>
                        <div class="list">
                            <div class="item">
                                个别时候，比如返回的数据的第二组（可能是热门或者推荐之类的），会没有reply_count字段，所以全部设置成0，最后再再pipeline中集中处理。
                            </div>
                            <div class="item">
                                环球时代 满天名没有爬取视频这个板块，所以就没有视频。。。。。。干得漂亮！！！！你这么放肆好不好,所以所有的板块我都没有添加video_urls处理函数。
                            </div>
                            <div class="item">
                                满天名没有抓评论！！！
                            </div>



                        </div>
                        <h2>
                            今日头条
                        </h2>
                        <div class="list">
                            <div class="item">
                                今日头条还是抓取手机网页版，因为反正不管什么版本，它的内容都会变化，不是固定的。也就是说重复请求可能会有重复的，所以今日头条的爬取策略应当适当的多设置一些，爬取频繁一些。
                            </div>
                            <div class="item">
                                网页版编写过程中，已经计算出了今日头条url链接中的as字段和cp字段。然后_signature字段应该也计算得出来，不过直接加时间戳也能用，所以就不计算了。
                            </div>
                            <div class="item">
                                满天名的今日头条一共只有5个板块，打算重新配置一下板块设置，注意今日头条的启动方式应当不一样。
                            </div>
                            <div class="item">
                                今日头条的评论也是不准确的，里边的评论数也包括了点赞数。
                            </div>
                            <div class="item">
                                满天明的代码里，评论只有一次请求，没有二次请求。
                            </div>
                            <div class="item">
                                评论里，请求中有一个has_more可以来判断请求是否结束了。
                            </div>
                            <div class="item">
                                所有的评论的数据不一定规范。
                            </div>

                        </div>
                        <h2>
                            zaker
                        </h2>
                        <div class="list">
                            <div class="item">
                                zaker中的新闻跟今日头条也是一样的。每次刷新内容都是不一样的
                            </div>
                            <div class="item">
                                满天明给的新闻板块竟然只有一个，而事实也确实只有一个
                            </div>

                        </div>
                        <h2>
                            畅读
                        </h2>
                        <div class="list">
                            <div class="item">
                                抓不到评论信息，他留下的评论接口有问题。
                            </div>
                            <div class="item">
                                暂时没做评论抓取功能，因为实在找不到评论的接口，已经有了抓取评论的功能了，只是没有抓取下一页的
                            </div>
                        </div>
                        <h2>
                            Sina
                        </h2>
                        <div class="list">
                            <div class="item">
                                新浪的board中，返回的字段不全。每一个最后都加一个判断
                            </div>
                            <div class="item">
                                新浪的url是直接抓的app的链接，链接里边的字段都不能改变，还不能少，所以实在没有找到突破方法，只有将原来是什么样子的就是什么样子的url给拷贝出来。
                            </div>
                            <div class="item">
                                新浪的url板块名字和发起的url之间的名字对应不上，而且如果改了数据库，那么原来的爬虫就要改变，如果没有改数据库，那么就要在start_requests方法中自动生成相应的url
                            </div>
                            <div class="item">
                                新浪请求中的rand字段不是random的，会报错，所以不要乱改。
                            </div>

                        </div>

                    </div>
                </div>
            </div>
            </div>
</div>


</body>
</html>